# News Impact — агрегатор найчастіше згаданих новин (GenAI)

> Кешує RSS/Atom з багатьох ЗМІ, перекладає контент англійською один раз (із кешем), кластеризує сюжети за ембеддингами, дедуплікує згадки за **реєстрабельним доменом** (eTLD+1), обирає **Top‑N** найчастіше згаданих тем та генерує стислий, нейтральний підсумок (OpenAI).

![Скріншот UI](./screenshot.png)

---

## Мотивація та ціль
- **Проблема:** інфошум у медіа; важко зрозуміти, **які теми реально домінують** одночасно в кількох виданнях.
- **Ціль:** автоматично виявляти **найчастіше згадані сюжети** між різними ЗМІ та подавати короткі резюме з посиланнями.

## Короткий огляд підходів (Introduction)
- Класичні агрегатори показують стрічку заголовків або ранжують за кліками, але не виявляють **однакові сюжети** між виданнями.
- Ми поєднуємо **семантичні ембеддинги** (Sentence Transformers) з **кластеризацією** заголовків і **LLM‑перекладом** для багатомовних джерел.

## Технічний опис (Description)
**Пайплайн:**
1. **Ingest & Cache.** Збір RSS/Atom → `out/titles_cache.json` (заголовки) і `out/articles_cache.json` (тіла). Кастомний User‑Agent; м’яка обробка 404.
2. **Переклад (idempotent).** OpenAI → `title_en`/`body_en` + sha1 оригіналу та мітки моделі/часу (уникає повторних витрат).
3. **Ембеддинги.** `all-MiniLM-L6-v2` на `title_en` (fallback `title`).
4. **Кластеризація.** Жадібно за косинусом (поріг налаштовується), формує сюжети.
5. **Дедуп за eTLD+1.** У межах сюжету залишаємо **одне посилання на видання** (`nv.ua`, `bbc.com`, …), незалежно від піддомену.
6. **Резюме.** OpenAI (`gpt-4.1-mini`, `temperature=0`) → 2–3 речення, нейтрально.
7. **UI.** Streamlit: кнопки **Update cache** / **Summarize**; вкладки **Top stories** та **All titles** (ієрархія «домен → піддомени», якщо піддоменів >1).

**Ключові фічі:**
- Переклад і резюме з **кешем** (sha1) — не платимо повторно за однаковий текст.
- **AMP‑fallback** і **рефетч коротких статей** для кращого видобутку контенту.
- Вивід Top‑N із лінками формату **[ДОМЕН] Назва статті**.

## Демонстрація (Demo)
- **Top stories:** сюжети з резюме та переліком лінків (по одному на видання).
- **All titles:** групування за реєстрабельним доменом; всередині — піддомени/рубрики; якщо піддомен один — показуємо один рівень.

## Результати (Results)
Показники беруться з отриманих файлів/логів (без «на око»):
- **Coverage:** `items_ingested`, кількість кластерів (`groups`).  
- **Cross‑outlet spread:** середня/медіана кількості унікальних доменів у Top‑N.  
- **Extraction rate:** частка `body_len>0` у `articles_cache.json`.  
- **Translation rate:** частка записів із `title_en` у `titles_cache.json`.  
- **Вартість/латентність:** кількість **нових** перекладів/резюме за запуск × тарифи API.

## Висновки та майбутня робота (Conclusions)
- Підхід дає стислий, релевантний дайджест **спільних сюжетів** між ЗМІ.  
- Переклад (idempotent) + дедуп за eTLD+1 критично підвищують якість.  
- Далі: агломеративна кластеризація, headless‑рендер для JS‑сайтів, тематична класифікація, історичні тренди.

---

## Інструкції з запуску (README‑частина)
### Вимоги
- Python 3.11 (рекомендовано conda/mamba).
- Файл `.env` у корені з ключем OpenAI:
```
OPENAI_API_KEY=sk-...
```

### Встановлення
```bash
mamba env create -f requirements.yml
mamba activate news-impact
# або оновлення середовища
mamba env update -f requirements.yml -n news-impact
```

### Запуск UI
```bash
streamlit run streamline.py
```
**Кроки в UI:**  
- **Update cache** → збір новин, витяг статей, переклад (разово), оновлення кешів.  
- **Summarize** → ембеддинг/кластеризація, Top‑N, LLM‑резюме, запис `out/report.json`.

### Запуск із CLI (опційно)
```bash
python -m src.main \
  --out out/report.json \
  --titles-dir out \
  --max-items 600 \
  --max-age-hours 48 \
  --sim-thr 0.72 \
  --topk 5 \
  --oa-model gpt-4.1-mini \
  --translate-bodies \
  --log-level INFO
```

### Налаштування логів
```bash
export NEWSIMPACT_LOG=DEBUG   # для Streamlit
# або
python -m src.main --log-level DEBUG
```

### Структура репозиторію
```
.
├── src/
│   └── main.py               # пайплайн: ingest → translate → cluster → summarize (+логування)
├── streamline.py             # Streamlit UI (контроли, вкладки, авто-завантаження звіту)
├── requirements.yml          # conda‑середовище
├── .env                      # OPENAI_API_KEY
└── out/
    ├── titles_cache.json     # кеш заголовків (з title_en*)
    ├── articles_cache.json   # кеш статей (з body_en*, body_len, fetched_at)
    └── report.json           # підсумковий Top‑N
```

---

## Короткий опис алгоритмів і моделей
- **Екстракція новин:** `feedparser` з користувацьким User‑Agent + fallback `requests`.
- **Витяг текстів:** `BeautifulSoup` + евристики + **AMP‑fallback**; рефетч коротких/порожніх записів.
- **Переклад/резюме:** OpenAI `gpt-4.1-mini`, `temperature=0`, кеш `*_en` із sha1.  
- **Ембеддинги:** `sentence-transformers/all-MiniLM-L6-v2`.  
- **Кластеризація:** косинус, жадібна; поріг керується з UI.  
- **Дедуп у сюжеті:** за eTLD+1 (`tldextract`).  
- **UI:** Streamlit; лінки у форматі **[ДОМЕН] Назва**.
